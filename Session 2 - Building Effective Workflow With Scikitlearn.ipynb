{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Session 1**\n",
    "\n",
    "- Review of the basic ML workflow\n",
    "- Encoding categorical variable\n",
    "- Using Column Transfer and Pipeline\n",
    "- Encoding Text Data\n",
    "\n",
    "**Session 2**\n",
    "- Handling missing value\n",
    "- Switching to the full dataset\n",
    "- Recap\n",
    "- Evaluating and tuning a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starter Code ( Copy From Here: http://bit.ly/first-ml-lesson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain', nrows=10)\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest', nrows=10)\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>male</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "5      0   8.4583        Q    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name   Age  \n",
       "0                            Braund, Mr. Owen Harris  22.0  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  \n",
       "2                             Heikkinen, Miss. Laina  26.0  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  \n",
       "4                           Allen, Mr. William Henry  35.0  \n",
       "5                                   Moran, Mr. James   NaN  \n",
       "6                            McCarthy, Mr. Timothy J  54.0  \n",
       "7                     Palsson, Master. Gosta Leonard   2.0  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  14.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The pipe.fit() step failed and gave an error because there are NaNs.\n",
    "- Scikitlearn models don't accept data with missing values with one exception which is **Histogram Based Gradient Boosting Trees**. It is for classification and regression.\n",
    "- It explicitly handles missing values without imputing them. So for this model alone you can use data with missing values and it will handle it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **X.dropna()**, drops all the rows missing values.\n",
    "- This might be a good option under two conditions,\n",
    "  - If you know that you will be loosing very litte or considerable amount of data by doing this.\n",
    "  - If the missing values are completely at random.\n",
    "- But in the vast majority of cases this is not an ideal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name   Age  \n",
       "0                            Braund, Mr. Owen Harris  22.0  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  \n",
       "2                             Heikkinen, Miss. Laina  26.0  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  \n",
       "4                           Allen, Mr. William Henry  35.0  \n",
       "6                            McCarthy, Mr. Timothy J  54.0  \n",
       "7                     Palsson, Master. Gosta Leonard   2.0  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  14.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do this before splitting into X and y so that drop the rows in the target column as well.\n",
    "X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>male</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "5      0   8.4583        Q    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name  \n",
       "0                            Braund, Mr. Owen Harris  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  \n",
       "2                             Heikkinen, Miss. Laina  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  \n",
       "4                           Allen, Mr. William Henry  \n",
       "5                                   Moran, Mr. James  \n",
       "6                            McCarthy, Mr. Timothy J  \n",
       "7                     Palsson, Master. Gosta Leonard  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To completely drop a columns with missing values\n",
    "X.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation** : Imputing missing values is filling in data from known parts of the data. When you are imputing missing values, you are making up data.\n",
    "\n",
    "**Caveats** : Imputation could be a course or a book on it's own, but we are not going to see that in depth here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing Missing Values Using Scikitlearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default it uses the **mean** of that column to impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ],\n",
       "       [38.        ],\n",
       "       [26.        ],\n",
       "       [35.        ],\n",
       "       [35.        ],\n",
       "       [28.11111111],\n",
       "       [54.        ],\n",
       "       [ 2.        ],\n",
       "       [27.        ],\n",
       "       [14.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.fit_transform(X[['Age']]) # 2D input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.11111111])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can be used to check the value it learned or used to impute missing value.\n",
    "imp.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x48 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 88 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('onehotencoder',\n",
       "                                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                                dtype=<class 'numpy.float64'>,\n",
       "                                                handle_unknown='error',\n",
       "                                                sparse=True),\n",
       "                                  ['Embarked', 'Sex']),\n",
       "                                 ('countvectorizer',\n",
       "                                  CountVectorizer(analyzer='word', binary=False,\n",
       "                                                  decode_error='strict',\n",
       "                                                  dtype=...\n",
       "                                                  input='content',\n",
       "                                                  lowercase=True, max_df=1.0,\n",
       "                                                  max_features=None, min_df=1,\n",
       "                                                  ngram_range=(1, 1),\n",
       "                                                  preprocessor=None,\n",
       "                                                  stop_words=None,\n",
       "                                                  strip_accents=None,\n",
       "                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                  tokenizer=None,\n",
       "                                                  vocabulary=None),\n",
       "                                  'Name'),\n",
       "                                 ('simpleimputer',\n",
       "                                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                                fill_value=None,\n",
       "                                                missing_values=nan,\n",
       "                                                strategy='mean', verbose=0),\n",
       "                                  ['Age'])],\n",
       "                   verbose=False),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=1, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                    warm_start=False)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If X_new does not have any missing values, then nothing gets imputed in the new data.\n",
    "- If X_new has missing values then it get's imputed with the mean (or median, etc) of X and not with the mean of X_new. 28.11 in our case.\n",
    "\n",
    "**YOU CAN ONLY LEARN FROM THE TRAINING DATA AND NOT FROM THE TESTING OR OUT OF SAMPLE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = df_new[cols]\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip** : \n",
    "You can also create a new feature out of missing values. The column would have a 0 and 1 to indicate missing values. This can be useful when your missing values but not at random. In some cases data with missing values can also be a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicates missing values as 0 and 1\n",
    "imp_indicator = SimpleImputer(add_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  0.        ],\n",
       "       [38.        ,  0.        ],\n",
       "       [26.        ,  0.        ],\n",
       "       [35.        ,  0.        ],\n",
       "       [35.        ,  0.        ],\n",
       "       [28.11111111,  1.        ],\n",
       "       [54.        ,  0.        ],\n",
       "       [ 2.        ,  0.        ],\n",
       "       [27.        ,  0.        ],\n",
       "       [14.        ,  0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_indicator.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Tip** : You can write some custom code to try out multiple models at once. But you could also use Stack Classifier or Voting Classifier which produces a combined output of multiple models and does not really give you the option to compare the output of every model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 - Switching To Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest')\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have a problem with missing values**\n",
    "- The trianing set has missing values in *Embarked* column, but the testing set doesn't.\n",
    "- The training set does not have missing values in *Fare* column, but the testing set has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data Into X and y\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Column Transformer\n",
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get an error saying there are NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have to Impute Missing Values**. Our solution is to impute missing values before One-Hot-Encoding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While imputing a string column like below, you can't use the **mean** or **median** option.\n",
    "- We have two options - 1) impute the **mode** also called as **most frequent** value. 2) Is to impute a **constant** value of your choice.\n",
    "- We are going to try out option 2. In this way missing values become another categories among the existing categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Addressing first problem, where we have missing values in Train but not Test (Embarked).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_constant = SimpleImputer(strategy='constant',fill_value='missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the like below, we are building a **Transformer-Only** pipeline just for example.\n",
    "- In the pipeline below, we have first treates the mising values and then encoded using OHE on the *Embarked* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you added **imp_constant** and **ohe** separately and directly into the **Column Transformer** instead of making a pipeline and then passing it into the **Column Transformer**?? \n",
    "\n",
    "The problem is, the **imputation** step will output two columns and the **ohe** will output multiple columns and you will end up having columns which are not suitale for the final step. So it's much more clear and safe to use it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_ohe.fit_transform(X[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules For Pipeline**\n",
    "- All pipeline steps except for the final step **must** be a **Transformer**.\n",
    "- The final step can be a **Transformer** or a **Model**.\n",
    "- When we use a pipeline which ends in a **model** we use the methods **fit()** to fit the pipeline and **predict()** to predict on the new data.\n",
    "- When we use a pipeline which ends in a **transformer** we use the methods **fit_transform()** on training data and **transform()** on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making changes to the old Column Transformer in the line below**\n",
    "- We have used **imp_ohe** here, so what does **imp_ohe** contain? Remember we build a pipeline of transformers which imputed missing values and then applied one-hot? Yes so we are taking that pipeline adding to *make_column_transformer*, to the columns where we need to impute missing values and one-hot encode it. \n",
    "- In the example below *Embarked* has missing values but *Sex* does not, it doesn't matter to apply the pipeline which imputes missing values nothing will happen to *Sex* column as it does not have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x1518 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Addressing second problem, where we have missing values in Test but not Train (Fare).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are taking the column transformer and adding *Fare* in the *imp* instance we created along with *Age*. Note *Fare* is a numerical column.\n",
    "- So what happens is, in the *fit()* section the *imputer* learns the *mean* of *Fare* and if at all it sees any missing values in Test data it imputes it with the *mean* it learned from the *Test* data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age','Fare']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x1518 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update our pipeline\n",
    "\n",
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = df_new[cols]\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "413    0\n",
       "414    1\n",
       "415    0\n",
       "416    0\n",
       "417    1\n",
       "Length: 418, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can attach the predictions with the index by doing something like this\n",
    "pd.Series(pipe.predict(X_new),index=df_new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.69911765, 32.20420797])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to get the statistics out\n",
    "ct.named_transformers_.simpleimputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['missing', 'missing'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to get the statistics out\n",
    "ct.named_transformers_.pipeline.named_steps.simpleimputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap at http://bit.ly/complex-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest')\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_constant = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)\n",
    "vect = CountVectorizer()\n",
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawbacks of doing your pre-processing in Pandas**\n",
    "\n",
    "1) You can't make use of *CountVectorizer()* which helps you work with *text* data.\n",
    "\n",
    "2) You can do you *OneHotEncoding* in Pandas using *GetDummies* method, but what this does is it adds the columns or the changes are made directly to the original dataframe. But using Scikit-Learn the original dataframe is untouched and clean to explore. Scikit-learn also saves memory space.\n",
    "\n",
    "3) If you do your missing value imputation using Pandas, it leads to **Data Leakage**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Leakage**\n",
    "\n",
    "When you use a *Model Evaluation* procedure such as *TrainTest split* or *CrossValidation* that is supposed to simulate the future so that you can estimate right now how your model will perform in the future. That is what a *Model Evaluation* procedure is for. For example you use *Model Evaluation* procedure to check whether you are *Overfitting* your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do your missing value imputation in *Pandas* and then pass it to your model, then the model learns something it is not supposed to learn. The scores become unreliable. Your *Model Evaluation* will not be a simulation of reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So some Transformations like *missing value value imputation*, *Feature Encoding*, *onehot* not all shouldn't be done using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary Of Data Leakage**\n",
    "\n",
    "- Data Leakage is learning something from the testing data that you are not allowed to know.\n",
    "- Why should you avoid Data Leakage? Because the scores become unreliable and you end up taking bad decsions for Hyperparameter tuning and bad decsions on how well the model is performing.\n",
    "- How does Scikit-Learn prevent Data Leakage? It has separate Fit and Fit-Transform steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can avoid Data Leakage using Pandas Transformations if your first step is Train-Test-Split**, but it is a huge pain in complex cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114619295712762"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening behind?\n",
    "\n",
    "- CV is splitting the data into 5 sets. So each time a set get's to act like the test data.\n",
    "- So for 4 portions of the data *Column Transformer* is applied and the *model* is fit and predictions are made on the last portion of data.\n",
    "- This is repeated for all the sets.\n",
    "- So won't Data Leakage happen here?\n",
    "- CV splits the data and then applies the transformations, it does not apple the transformations to the entire data and then split. In this way we won't have Data Leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: We are going to be tuning a pipeline, so we should know the step names inside the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['columntransformer', 'logisticregression'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2:The Parameters go in a dictionary, so we are going to build a dictionary containing the parameters and the values to be tried out while tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How you create a dictionary for hyperparameter tuning is, you give the *step* name followed by double underscores and then the *parameter* name. For example **logisticregression** is the step name and **penalty** is the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__penalty': ['l1', 'l2'],\n",
       " 'logisticregression__C': [0.1, 1, 10]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params['logisticregression__penalty'] = ['l1','l2']\n",
    "params['logisticregression__C'] = [0.1, 1, 10]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030163</td>\n",
       "      <td>0.020577</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025138</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.821537</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.030163      0.020577         0.007181        0.000746   \n",
       "1       0.017154      0.002475         0.006782        0.001324   \n",
       "2       0.019148      0.001466         0.006783        0.000399   \n",
       "3       0.016959      0.000631         0.006386        0.000482   \n",
       "4       0.025138      0.003444         0.006593        0.000476   \n",
       "5       0.018344      0.000477         0.005994        0.000015   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                         0.1                                l1   \n",
       "1                         0.1                                l2   \n",
       "2                           1                                l1   \n",
       "3                           1                                l2   \n",
       "4                          10                                l1   \n",
       "5                          10                                l2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.787709   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.798883   \n",
       "2  {'logisticregression__C': 1, 'logisticregressi...           0.815642   \n",
       "3  {'logisticregression__C': 1, 'logisticregressi...           0.798883   \n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.832402   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.782123   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.803371           0.769663           0.758427           0.797753   \n",
       "1           0.803371           0.764045           0.775281           0.803371   \n",
       "2           0.820225           0.797753           0.792135           0.848315   \n",
       "3           0.825843           0.803371           0.786517           0.842697   \n",
       "4           0.814607           0.820225           0.786517           0.853933   \n",
       "5           0.803371           0.808989           0.797753           0.853933   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.783385        0.016946                6  \n",
       "1         0.788990        0.016258                5  \n",
       "2         0.814814        0.019787                2  \n",
       "3         0.811462        0.020141                3  \n",
       "4         0.821537        0.022107                1  \n",
       "5         0.809234        0.024080                4  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025138</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.821537</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030163</td>\n",
       "      <td>0.020577</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       0.025138      0.003444         0.006593        0.000476   \n",
       "2       0.019148      0.001466         0.006783        0.000399   \n",
       "3       0.016959      0.000631         0.006386        0.000482   \n",
       "5       0.018344      0.000477         0.005994        0.000015   \n",
       "1       0.017154      0.002475         0.006782        0.001324   \n",
       "0       0.030163      0.020577         0.007181        0.000746   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "4                          10                                l1   \n",
       "2                           1                                l1   \n",
       "3                           1                                l2   \n",
       "5                          10                                l2   \n",
       "1                         0.1                                l2   \n",
       "0                         0.1                                l1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.832402   \n",
       "2  {'logisticregression__C': 1, 'logisticregressi...           0.815642   \n",
       "3  {'logisticregression__C': 1, 'logisticregressi...           0.798883   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.782123   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.798883   \n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.787709   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "4           0.814607           0.820225           0.786517           0.853933   \n",
       "2           0.820225           0.797753           0.792135           0.848315   \n",
       "3           0.825843           0.803371           0.786517           0.842697   \n",
       "5           0.803371           0.808989           0.797753           0.853933   \n",
       "1           0.803371           0.764045           0.775281           0.803371   \n",
       "0           0.803371           0.769663           0.758427           0.797753   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "4         0.821537        0.022107                1  \n",
       "2         0.814814        0.019787                2  \n",
       "3         0.811462        0.020141                3  \n",
       "5         0.809234        0.024080                4  \n",
       "1         0.788990        0.016258                5  \n",
       "0         0.783385        0.016946                6  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                fill_value='missing', missing_values=nan,\n",
       "                                strategy='constant', verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=True))],\n",
       "          verbose=False),\n",
       " 'countvectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None),\n",
       " 'simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='mean', verbose=0),\n",
       " 'remainder': 'passthrough'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see all the parameters using this line of code\n",
    "pipe.named_steps.columntransformer.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use parameter tuning if you do transformations using Scikit-Learn\n",
    "params['columntransformer__pipeline__onehotencoder__drop'] = [None,'first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning CountVectorizer\n",
    "params['columntransformer__countvectorizer__ngram_range'] = [(1,1),(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Imputer\n",
    "params['columntransformer__simpleimputer__add_indicator'] = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__penalty': ['l1', 'l2'],\n",
       " 'logisticregression__C': [0.1, 1, 10],\n",
       " 'columntransformer__pipeline__onehotencoder__drop': [None, 'first'],\n",
       " 'columntransformer__countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       " 'columntransformer__simpleimputer__add_indicator': [False, True]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_columntransformer__countvectorizer__ngram_range</th>\n",
       "      <th>param_columntransformer__pipeline__onehotencoder__drop</th>\n",
       "      <th>param_columntransformer__simpleimputer__add_indicator</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.035727</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.830494</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.826012</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.038306</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.826006</td>\n",
       "      <td>0.027231</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.824895</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.821537</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.031535</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.817055</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814820</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.025202</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814820</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.024574</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.811481</td>\n",
       "      <td>0.031065</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.811468</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.024509</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.811449</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.018368</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.810363</td>\n",
       "      <td>0.032182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032358</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.810332</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.024139</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.025357</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.019747</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809215</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.808104</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.022819</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.808097</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.026275</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.806980</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.024974</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.805844</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.805844</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.022718</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.804739</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.794608</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.019753</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.793484</td>\n",
       "      <td>0.017253</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.018099</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.791243</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.790114</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.255192</td>\n",
       "      <td>2.466038</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.788996</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.787885</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039184</td>\n",
       "      <td>0.042465</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.028925</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "28       0.035727      0.001691         0.007772        0.000970   \n",
       "40       0.048680      0.003254         0.008577        0.000490   \n",
       "34       0.038306      0.002715         0.007390        0.000481   \n",
       "46       0.046155      0.005934         0.007992        0.000884   \n",
       "4        0.026372      0.002409         0.006780        0.000398   \n",
       "22       0.032313      0.005070         0.006392        0.000500   \n",
       "16       0.031535      0.003418         0.006384        0.000487   \n",
       "10       0.027539      0.003587         0.007766        0.001701   \n",
       "20       0.019470      0.000448         0.006982        0.000631   \n",
       "44       0.025202      0.001083         0.007246        0.000395   \n",
       "2        0.020361      0.001740         0.008977        0.004511   \n",
       "47       0.028155      0.003257         0.008148        0.000771   \n",
       "8        0.021351      0.001493         0.007392        0.000480   \n",
       "38       0.024574      0.000811         0.006996        0.000021   \n",
       "14       0.020156      0.001139         0.007164        0.000390   \n",
       "11       0.018551      0.000490         0.006685        0.000375   \n",
       "21       0.018257      0.001175         0.007374        0.001355   \n",
       "3        0.017414      0.000455         0.006606        0.000492   \n",
       "26       0.024509      0.000820         0.007792        0.000716   \n",
       "23       0.018368      0.000476         0.006959        0.000632   \n",
       "9        0.032358      0.022801         0.008778        0.003177   \n",
       "15       0.019936      0.001067         0.007388        0.000482   \n",
       "17       0.018753      0.001148         0.006414        0.000497   \n",
       "35       0.024139      0.000756         0.007191        0.000398   \n",
       "5        0.019747      0.001466         0.006982        0.000631   \n",
       "32       0.025325      0.001482         0.007590        0.000499   \n",
       "29       0.026525      0.001197         0.008300        0.000412   \n",
       "45       0.022819      0.000471         0.007223        0.000380   \n",
       "41       0.026275      0.003141         0.007792        0.000749   \n",
       "39       0.024974      0.002784         0.007586        0.000794   \n",
       "27       0.022729      0.000372         0.007591        0.000781   \n",
       "33       0.022718      0.000733         0.007396        0.000492   \n",
       "31       0.022144      0.001465         0.007880        0.000806   \n",
       "7        0.019753      0.000743         0.007487        0.000629   \n",
       "19       0.018099      0.002441         0.006629        0.000903   \n",
       "43       0.024432      0.002461         0.008188        0.000769   \n",
       "37       0.023344      0.002236         0.014611        0.014750   \n",
       "25       1.255192      2.466038         0.007003        0.000873   \n",
       "1        0.017741      0.001324         0.008590        0.002796   \n",
       "13       0.017724      0.001176         0.007394        0.000494   \n",
       "0        0.141177      0.219707         0.026028        0.038076   \n",
       "30       0.023457      0.002081         0.007862        0.000659   \n",
       "24       0.025877      0.005039         0.012813        0.011694   \n",
       "6        0.039184      0.042465         0.007380        0.000489   \n",
       "36       0.022729      0.001718         0.007777        0.001323   \n",
       "42       0.028925      0.006014         0.008699        0.000651   \n",
       "12       0.017730      0.000407         0.011183        0.006983   \n",
       "18       0.016989      0.000828         0.006604        0.000506   \n",
       "\n",
       "   param_columntransformer__countvectorizer__ngram_range  \\\n",
       "28                                             (1, 2)      \n",
       "40                                             (1, 2)      \n",
       "34                                             (1, 2)      \n",
       "46                                             (1, 2)      \n",
       "4                                              (1, 1)      \n",
       "22                                             (1, 1)      \n",
       "16                                             (1, 1)      \n",
       "10                                             (1, 1)      \n",
       "20                                             (1, 1)      \n",
       "44                                             (1, 2)      \n",
       "2                                              (1, 1)      \n",
       "47                                             (1, 2)      \n",
       "8                                              (1, 1)      \n",
       "38                                             (1, 2)      \n",
       "14                                             (1, 1)      \n",
       "11                                             (1, 1)      \n",
       "21                                             (1, 1)      \n",
       "3                                              (1, 1)      \n",
       "26                                             (1, 2)      \n",
       "23                                             (1, 1)      \n",
       "9                                              (1, 1)      \n",
       "15                                             (1, 1)      \n",
       "17                                             (1, 1)      \n",
       "35                                             (1, 2)      \n",
       "5                                              (1, 1)      \n",
       "32                                             (1, 2)      \n",
       "29                                             (1, 2)      \n",
       "45                                             (1, 2)      \n",
       "41                                             (1, 2)      \n",
       "39                                             (1, 2)      \n",
       "27                                             (1, 2)      \n",
       "33                                             (1, 2)      \n",
       "31                                             (1, 2)      \n",
       "7                                              (1, 1)      \n",
       "19                                             (1, 1)      \n",
       "43                                             (1, 2)      \n",
       "37                                             (1, 2)      \n",
       "25                                             (1, 2)      \n",
       "1                                              (1, 1)      \n",
       "13                                             (1, 1)      \n",
       "0                                              (1, 1)      \n",
       "30                                             (1, 2)      \n",
       "24                                             (1, 2)      \n",
       "6                                              (1, 1)      \n",
       "36                                             (1, 2)      \n",
       "42                                             (1, 2)      \n",
       "12                                             (1, 1)      \n",
       "18                                             (1, 1)      \n",
       "\n",
       "   param_columntransformer__pipeline__onehotencoder__drop  \\\n",
       "28                                               None       \n",
       "40                                              first       \n",
       "34                                               None       \n",
       "46                                              first       \n",
       "4                                                None       \n",
       "22                                              first       \n",
       "16                                              first       \n",
       "10                                               None       \n",
       "20                                              first       \n",
       "44                                              first       \n",
       "2                                                None       \n",
       "47                                              first       \n",
       "8                                                None       \n",
       "38                                              first       \n",
       "14                                              first       \n",
       "11                                               None       \n",
       "21                                              first       \n",
       "3                                                None       \n",
       "26                                               None       \n",
       "23                                              first       \n",
       "9                                                None       \n",
       "15                                              first       \n",
       "17                                              first       \n",
       "35                                               None       \n",
       "5                                                None       \n",
       "32                                               None       \n",
       "29                                               None       \n",
       "45                                              first       \n",
       "41                                              first       \n",
       "39                                              first       \n",
       "27                                               None       \n",
       "33                                               None       \n",
       "31                                               None       \n",
       "7                                                None       \n",
       "19                                              first       \n",
       "43                                              first       \n",
       "37                                              first       \n",
       "25                                               None       \n",
       "1                                                None       \n",
       "13                                              first       \n",
       "0                                                None       \n",
       "30                                               None       \n",
       "24                                               None       \n",
       "6                                                None       \n",
       "36                                              first       \n",
       "42                                              first       \n",
       "12                                              first       \n",
       "18                                              first       \n",
       "\n",
       "   param_columntransformer__simpleimputer__add_indicator  \\\n",
       "28                                              False      \n",
       "40                                              False      \n",
       "34                                               True      \n",
       "46                                               True      \n",
       "4                                               False      \n",
       "22                                               True      \n",
       "16                                              False      \n",
       "10                                               True      \n",
       "20                                               True      \n",
       "44                                               True      \n",
       "2                                               False      \n",
       "47                                               True      \n",
       "8                                                True      \n",
       "38                                              False      \n",
       "14                                              False      \n",
       "11                                               True      \n",
       "21                                               True      \n",
       "3                                               False      \n",
       "26                                              False      \n",
       "23                                               True      \n",
       "9                                                True      \n",
       "15                                              False      \n",
       "17                                              False      \n",
       "35                                               True      \n",
       "5                                               False      \n",
       "32                                               True      \n",
       "29                                              False      \n",
       "45                                               True      \n",
       "41                                              False      \n",
       "39                                              False      \n",
       "27                                              False      \n",
       "33                                               True      \n",
       "31                                               True      \n",
       "7                                                True      \n",
       "19                                               True      \n",
       "43                                               True      \n",
       "37                                              False      \n",
       "25                                              False      \n",
       "1                                               False      \n",
       "13                                              False      \n",
       "0                                               False      \n",
       "30                                               True      \n",
       "24                                              False      \n",
       "6                                                True      \n",
       "36                                              False      \n",
       "42                                               True      \n",
       "12                                              False      \n",
       "18                                               True      \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__penalty  \\\n",
       "28                          10                                l1   \n",
       "40                          10                                l1   \n",
       "34                          10                                l1   \n",
       "46                          10                                l1   \n",
       "4                           10                                l1   \n",
       "22                          10                                l1   \n",
       "16                          10                                l1   \n",
       "10                          10                                l1   \n",
       "20                           1                                l1   \n",
       "44                           1                                l1   \n",
       "2                            1                                l1   \n",
       "47                          10                                l2   \n",
       "8                            1                                l1   \n",
       "38                           1                                l1   \n",
       "14                           1                                l1   \n",
       "11                          10                                l2   \n",
       "21                           1                                l2   \n",
       "3                            1                                l2   \n",
       "26                           1                                l1   \n",
       "23                          10                                l2   \n",
       "9                            1                                l2   \n",
       "15                           1                                l2   \n",
       "17                          10                                l2   \n",
       "35                          10                                l2   \n",
       "5                           10                                l2   \n",
       "32                           1                                l1   \n",
       "29                          10                                l2   \n",
       "45                           1                                l2   \n",
       "41                          10                                l2   \n",
       "39                           1                                l2   \n",
       "27                           1                                l2   \n",
       "33                           1                                l2   \n",
       "31                         0.1                                l2   \n",
       "7                          0.1                                l2   \n",
       "19                         0.1                                l2   \n",
       "43                         0.1                                l2   \n",
       "37                         0.1                                l2   \n",
       "25                         0.1                                l2   \n",
       "1                          0.1                                l2   \n",
       "13                         0.1                                l2   \n",
       "0                          0.1                                l1   \n",
       "30                         0.1                                l1   \n",
       "24                         0.1                                l1   \n",
       "6                          0.1                                l1   \n",
       "36                         0.1                                l1   \n",
       "42                         0.1                                l1   \n",
       "12                         0.1                                l1   \n",
       "18                         0.1                                l1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "28  {'columntransformer__countvectorizer__ngram_ra...           0.860335   \n",
       "40  {'columntransformer__countvectorizer__ngram_ra...           0.849162   \n",
       "34  {'columntransformer__countvectorizer__ngram_ra...           0.854749   \n",
       "46  {'columntransformer__countvectorizer__ngram_ra...           0.843575   \n",
       "4   {'columntransformer__countvectorizer__ngram_ra...           0.832402   \n",
       "22  {'columntransformer__countvectorizer__ngram_ra...           0.821229   \n",
       "16  {'columntransformer__countvectorizer__ngram_ra...           0.826816   \n",
       "10  {'columntransformer__countvectorizer__ngram_ra...           0.821229   \n",
       "20  {'columntransformer__countvectorizer__ngram_ra...           0.810056   \n",
       "44  {'columntransformer__countvectorizer__ngram_ra...           0.810056   \n",
       "2   {'columntransformer__countvectorizer__ngram_ra...           0.815642   \n",
       "47  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "8   {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "38  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "14  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "11  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "21  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "3   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "26  {'columntransformer__countvectorizer__ngram_ra...           0.810056   \n",
       "23  {'columntransformer__countvectorizer__ngram_ra...           0.776536   \n",
       "9   {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "15  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "17  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "35  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "5   {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "32  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "29  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "45  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "41  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "39  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "27  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "33  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "31  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "7   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "19  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "43  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "37  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "25  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "1   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "13  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "0   {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "30  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "24  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "6   {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "36  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "42  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "12  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "18  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "28           0.825843           0.825843           0.780899   \n",
       "40           0.825843           0.814607           0.786517   \n",
       "34           0.820225           0.820225           0.780899   \n",
       "46           0.831461           0.814607           0.780899   \n",
       "4            0.814607           0.820225           0.786517   \n",
       "22           0.820225           0.814607           0.792135   \n",
       "16           0.820225           0.814607           0.780899   \n",
       "10           0.820225           0.808989           0.780899   \n",
       "20           0.820225           0.797753           0.792135   \n",
       "44           0.820225           0.797753           0.792135   \n",
       "2            0.820225           0.797753           0.792135   \n",
       "47           0.820225           0.820225           0.780899   \n",
       "8            0.820225           0.786517           0.792135   \n",
       "38           0.820225           0.797753           0.792135   \n",
       "14           0.820225           0.797753           0.792135   \n",
       "11           0.803371           0.808989           0.792135   \n",
       "21           0.820225           0.803371           0.786517   \n",
       "3            0.825843           0.803371           0.786517   \n",
       "26           0.820225           0.786517           0.792135   \n",
       "23           0.803371           0.808989           0.792135   \n",
       "9            0.825843           0.797753           0.786517   \n",
       "15           0.820225           0.803371           0.786517   \n",
       "17           0.803371           0.808989           0.797753   \n",
       "35           0.820225           0.814607           0.780899   \n",
       "5            0.803371           0.808989           0.797753   \n",
       "32           0.820225           0.780899           0.792135   \n",
       "29           0.814607           0.820225           0.780899   \n",
       "45           0.814607           0.797753           0.786517   \n",
       "41           0.814607           0.820225           0.780899   \n",
       "39           0.808989           0.797753           0.786517   \n",
       "27           0.814607           0.792135           0.786517   \n",
       "33           0.814607           0.792135           0.786517   \n",
       "31           0.803371           0.769663           0.786517   \n",
       "7            0.803371           0.764045           0.786517   \n",
       "19           0.803371           0.764045           0.780899   \n",
       "43           0.797753           0.764045           0.780899   \n",
       "37           0.803371           0.764045           0.780899   \n",
       "25           0.803371           0.764045           0.775281   \n",
       "1            0.803371           0.764045           0.775281   \n",
       "13           0.803371           0.764045           0.780899   \n",
       "0            0.803371           0.769663           0.758427   \n",
       "30           0.803371           0.769663           0.758427   \n",
       "24           0.803371           0.769663           0.758427   \n",
       "6            0.803371           0.769663           0.758427   \n",
       "36           0.797753           0.769663           0.758427   \n",
       "42           0.797753           0.769663           0.758427   \n",
       "12           0.797753           0.769663           0.758427   \n",
       "18           0.797753           0.769663           0.758427   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "28           0.859551         0.830494        0.029113                1  \n",
       "40           0.853933         0.826012        0.024517                2  \n",
       "34           0.853933         0.826006        0.027231                3  \n",
       "46           0.853933         0.824895        0.025600                4  \n",
       "4            0.853933         0.821537        0.022107                5  \n",
       "22           0.853933         0.820426        0.019787                6  \n",
       "16           0.853933         0.819296        0.023467                7  \n",
       "10           0.853933         0.817055        0.023494                8  \n",
       "20           0.853933         0.814820        0.021852                9  \n",
       "44           0.853933         0.814820        0.021852                9  \n",
       "2            0.848315         0.814814        0.019787               11  \n",
       "47           0.853933         0.812598        0.026265               12  \n",
       "8            0.859551         0.812579        0.026183               13  \n",
       "38           0.848315         0.812579        0.020194               14  \n",
       "14           0.848315         0.812579        0.020194               14  \n",
       "11           0.870787         0.811481        0.031065               16  \n",
       "21           0.853933         0.811468        0.024076               17  \n",
       "3            0.842697         0.811462        0.020141               18  \n",
       "26           0.848315         0.811449        0.022058               19  \n",
       "23           0.870787         0.810363        0.032182               20  \n",
       "9            0.848315         0.810345        0.023233               21  \n",
       "15           0.837079         0.810332        0.017107               22  \n",
       "17           0.853933         0.809234        0.024080               23  \n",
       "35           0.848315         0.809234        0.025357               23  \n",
       "5            0.853933         0.809234        0.024080               23  \n",
       "32           0.853933         0.809215        0.025773               26  \n",
       "29           0.837079         0.808104        0.020904               27  \n",
       "45           0.848315         0.808097        0.022143               28  \n",
       "41           0.831461         0.806980        0.019414               29  \n",
       "39           0.837079         0.805844        0.017164               30  \n",
       "27           0.837079         0.805844        0.018234               30  \n",
       "33           0.848315         0.804739        0.024489               32  \n",
       "31           0.814607         0.794608        0.015380               33  \n",
       "7            0.814607         0.793484        0.017253               34  \n",
       "19           0.814607         0.791243        0.017572               35  \n",
       "43           0.808989         0.790114        0.015849               36  \n",
       "37           0.808989         0.789003        0.016100               37  \n",
       "25           0.808989         0.788996        0.016944               38  \n",
       "1            0.803371         0.788990        0.016258               39  \n",
       "13           0.808989         0.787885        0.016343               40  \n",
       "0            0.797753         0.783385        0.016946               41  \n",
       "30           0.797753         0.783385        0.016946               41  \n",
       "24           0.797753         0.783385        0.016946               41  \n",
       "6            0.797753         0.783385        0.016946               41  \n",
       "36           0.792135         0.777785        0.014779               45  \n",
       "42           0.792135         0.777785        0.014779               45  \n",
       "12           0.792135         0.777785        0.014779               45  \n",
       "18           0.792135         0.777785        0.014779               45  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304940053982801"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__countvectorizer__ngram_range': (1, 2),\n",
       " 'columntransformer__pipeline__onehotencoder__drop': None,\n",
       " 'columntransformer__simpleimputer__add_indicator': False,\n",
       " 'logisticregression__C': 10,\n",
       " 'logisticregression__penalty': 'l1'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid actually re-fits the model using the best parameters, so you can go ahead and predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
